# DS-SLAM

**1.针对问题**

- 动态环境

**2.主要贡献**

- 1、基于ORB-SLAM2 提出了动态环境中的完整语义SLAM系统（DS-SLAM），可以减少动态对象对位姿估计的影响。
- 2、一个实时语义分割网络放在一个独立的线程中，它将语义分割与运动一致性检测方法结合起来，过滤掉场景的动态部分。 在动态场景中，提升了定位模块和建图模块的稳定性和鲁棒性。
- 3、DS-SLAM创建了一个单独的线程来构建稠密的语义八叉树地图。 稠密的语义三维八叉树地图采用优势对数计分法滤除不稳定体素并更新这些体素的语义。

**3.解决方法**

![](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220514210717918.png?raw=true)

首先语义分割结果结合运动一致性检测去除动态特征点

- 运动一致性检测

1. 计算光流金字塔，得到当前帧中匹配的特征点。

   然后如果匹配对太接近图像的边缘或匹配对中心的像素差太大，匹配对将被丢弃。

3. 利用基本矩阵计算当前坐标系下的外极线。最后，确定匹配点到对应极线的距离是否小于某一阈值。如果距离大于阈值，则判定匹配点正在移动。



- 语义八叉树地图

  ![image-20220514211005130](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220514211005130.png?raw=true)

**4.不足之处**

**5.个人想法**

# Dyna-SLAM

**1.针对问题**

- 检测动态对象，防止跟踪算法使用动态对象来进行匹配；防止建立的地图里包含动态对象。

- 如何完善地图中被动态物体遮挡的部分。

**2.主要贡献**

- 1.在单目和双目情况下，使用Mask R-CNN对帧中的动态对象进行像素级分割，这样SLAM算法就不会提取这些对象上的特征。
- 2.在RGB-D的情况下，结合多视图几何和基于分割网络的算法来检测动态对象，并在从图像中移除它们后，用场景的正确信息修复被遮挡的背景。

**3.解决方法**

![image-20220514211416008](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220514211305660.png?raw=true)

- **low-cost Tracking**: 分割出潜在的动态对象之后，使用静态部分，寻找图像中静态部分的对应点，通过最小化重投影误差来优化相机位姿。

- ![image-20220514211305660](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220514211416008.png?raw=true)

  

**4.不足之处**

**5.个人想法**



# 基于语义先验和深度约束的室内动态场景 RGB-D SLAM 算法(信息与控制)

![image-20220407091939528](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220407091939528.png?raw=true)

![image-20220407092027657](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220407092027657.png?raw=true)

**1.针对问题**

- 动态场景位姿估计不准确、定位精度下降

**2.采用方法**

​     （由粗到精）

- 语义分割获得掩膜，得到潜在运动物体，得到静态特征点通过“RANSAC+归一化八点法”来估计初始化位姿。（语义分割去除一些误匹配的特征点，然后再利用RANSAC和八点法）
- 加权极线和深度约束的运动一致性检测算法（极线约束对于运动物体平行于相机运动，或者是沿相机的轴向方向运动等在极平面发生运动时，虽然其满足极线约束，实际上该物体却发生了运动。*结合深度约束可以得到当前帧的每个特征点的综合运动得分）

**3.效果**

- 实现了对动态场景下运 动特征点的剔除以及静态点云地图的拼接与更新

**4.不足**

- 弱纹理、弱光 照等复杂条件



# A New RGB-D SLAM Method



**1.针对问题**

- 动态室内环境处理动态物体

**2.采用方法**

- 几何约束、聚类、数学模型

  ![image-20220407092710506](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220407092710506.png?raw=true)

  1. 图像进行预处理 

     ​	RGB图像提取特征点，进行匹配，计算基础矩阵。深度图进行聚类。

  2. 动态物体检测和去除  

     ​    基于两个假设 （1）静态物体中有足够多的匹配（多于20对），（2）两帧之间视差小

        **数学模型**

     ​    两次基础矩阵约束，消除不匹配的点

     ![image-20220407092744095](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220407092744095.png?raw=true)

​				   动态物体上的动态特征点占有一定比例

![](https://github.com/pleasure-pan/paper/blob/image/blog/QQ%E6%88%AA%E5%9B%BE20220518195049.png?raw=true)

​					动态物体上的动态特征点占比大于一定阈值

![image-20220407092802131](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220407092802131.png?raw=true)

​					动态物体上剔除动态特征点后，其与特征点与图片中所有特征点比例将减小。

​					若某个深度聚类上的特征点满足以上三条，则视其为动态区域，并剔除其上所有特征点

**3.效果**

**4.不足**

#  RDS-SLAM: Real-Time Dynamic SLAM Using Semantic Segmentation Methods

- 1.**针对问题**

     语义SLAM 中tracking 线程要等待语义分割线程的结果，耗时

- **2.主要贡献**

  - (非阻塞模型)提出了一种新颖的基于语义的实时动态 vSLAM 算法 RDS-SLAM，它使跟踪线程不再需要等待语义结果。该方法有效地利用语义分割结果进行动态对象检测和异常值去除，同时保持算法的实时性。
  - 提出了一种关键帧选择策略，该策略尽可能使用最新的新语义信息，以统一的方式使用任何具有不同速度的语义分割方法去除异常值。

  ![](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220427200851425.png?raw=true)

  

- **3.解决方案**

  语义分割线程处理tracking线程产生的关键帧，

  通过语义信息对地图点的移动概率进行更新，用于tracking线程

  用关键帧队列里最之前的和最新的

  

- **4.不足之处**

  刚开始没有语义信息，前几帧是无法检测动态物体，（会不会有影响？）

- **5.个人想法**

   不需要等待语义分割很好 

# DP-SLAM: A visual SLAM with moving probability towards dynamic environments
**1.针对问题**

- 动态环境

**2.主要贡献**

- 语义信息和几何约束结合传播关键点移动概率
- 修复背景（DynaSLAM)

**3.解决方法**

![](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503191411307.png?raw=true)

![image-20220503193958529](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503193958529.png?raw=true)

- 语义分割

  sp表示特征点处于的标签 st表示特征点处于标签的集合 zt表示边界像素点集合



错误的分类在边界附近。 dist 求特征点到边界点的距离，再用估计 p i 的语义分割动态概率的二项式逻辑回归模型求P  p<0.75可能为静态点(即使处于mask里)

![image-20220503195945276](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503195945276.png?raw=true)





- 几何约束

  ![image-20220503200829693](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503200829693.png?raw=true)

RANSAC求F矩阵，求极线方程，

![image-20220503201017194](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503201017194.png?raw=true)

求距离，大于阈值判断为动点

![image-20220503201449637](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503201449637.png?raw=true)

- 迭代移动概率更新

  提出了一种移动概率传播算法，它结合了几何模型和基于深度学习的算法来从图像中删除动态对象。贝叶斯定理，利用过去和当前的信息来评估和消除动态关键点

  ![image-20220503202850501](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503202850501.png?raw=true)

  D(t)为特征点在t时刻的真实状态（1为动态）Nc为几何模块外点的数量，Ns为语义分割模块

  ![image-20220503204701453](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503204701453.png?raw=true)

假设动态概率传播具有马尔可夫性

![image-20220503205040606](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220503205040606.png?raw=true)

**4.不足之处**

**5.个人想法**

​	和师兄的概率传播不一样？





# CFP-SLAM: A Real-time Visual SLAM Based on Coarse-to-Fine Probability in Dynamic Environments
**1.针对问题**

- 实时性（绝大部分是语义分割+几何约束）

**2.主要贡献**

- 基于扩展卡尔曼滤波和匈牙利算法补偿漏检，用DBSCAN聚类算法区分前景点和背景点
- yolov5目标检测和几何约束获得高动态物体和低动态物体先验信息
- 特征点的静态移动概率从粗到细。两步计算概率

**3.解决方法**

![image-20220508191241014](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220508191241014.png?raw=true)

先用yolov5进行目标检测，对于漏检问题，采用EKF和匈牙利算法补偿漏检，关联相邻帧之间的框特征点提取后进行运动一致性检测（光流和对极约束）检测特征点静态概率；深度图聚类来区分前景点和背景点，得到粗略的特征点静态概率，再通过重投影约束和极线约束进行细化得到相机位姿。

- 

**4.不足之处**

**5.个人想法**

公式看的乱七八糟，也没看懂什么意思









# Detect-SLAM

**1.针对问题**

- 动态环境结合目标检测，共享语义信息

**2.主要贡献**

- 动态物体剔除
- 建立物体级地图

**3.解决方法**

- 动态物体剔除

​	![image-20220515142642742](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220515142642742.png?raw=true)

只对关键帧进行目标检测，得到检测结果更新地图点的移动概率。

![image-20220515145857507](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220515145857507.png?raw=true)

xi表示3D点。新特征点的初始值为0.5，St(xi)为关键帧中特征点的匹配状态。如果特征点在检测到的动态区域内St(xi)=1，否则为0。ɑ为影响因子0.3

- 概率传播方式（两种方式）

  1. 特征匹配 前后两帧特征点相匹配，进行概率传播，当一个特征点和局部地图里的3D点相匹配时，它的移动概率将和该3D点的概率相同。两者都满足，优先考虑局部地图3D点的概率。未匹配的点设置为0.5

     ![image-20220515152926093](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220515152926093.png?raw=true)

     θ is a threshold for feature matching

  2. 特征扩张 

     用于将高置信点（包括静态和动态点）扩张到未匹配的点。以半径为R

     ![image-20220515153231245](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220515153231245.png?raw=true)

​				r范围内所有高置信点的影响都算上  ![image-20220515155020783](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220515155020783.png?raw=true)表示距离因子。d>r时 为0.

![image-20220516084944](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516084944.png?raw=true)

- 地图构建

  1.预测区域ID 

  ​	检测区域和地图中区域是否是关联的（基于几何原理，如果是同一个物体，投影和检测是重合的）计算交并比

  ![image-20220516091340814](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516091340814.png?raw=true)

  如果IOU大于0.5，估计他们之间的深度似然

  ![image-20220516091502058](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516091502058.png?raw=true)

  

  ![image-20220516091746057](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516091746057.png?raw=true)

  Do和Dp代表在像素上观察到和投影的深度，N是重叠区域点云数量。

  2.去背景

    Grab − Cut  algorithm

-  SLAM-enhanced Detector

​			与传统的逐帧的目标检测方法相比，机器人在环境中多次从			不同的角度观察同一个对象。通过将重建后的三维环境中的			几何信息提供给目标检测，提高了目标检测的性能，保证了			目标检测在空间上的一致性

**4.不足之处**

**5.个人想法**

后续提高目标检测不是很明白

# SaD-SLAM: A Visual SLAM Based on Semantic and Depth Information
**1.针对问题**

- 动态环境导致位姿估计错误

**2.主要贡献**

- 基于特征点法的动态环境SLAM,提高位姿估计的准确度，动态环境下更稳定。
- 通过极线约束找到移动物体和可移动物体中的静态特征点用于位姿优化。提高位姿优化的准确性和稳定性。

**3.解决方法**

![image-20220516193534522](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516193534522.png?raw=true)

**输入为RGB图像，深度图像和掩膜**

- **Pose Initialization:**语义分割之后，有无法分割的物体，但是是可以移动的。如果检查一个特征点周围的五个像素和十个像素以外的点，在人或者椅子上，那么这个点就被判断为动态或者可移动的。

  通过最小化重投影误差来优化位姿。

- **Moving Consistency Testing:**跟踪连续五个连续帧中的可能移动特征点，都满足极线约束，视为静态特征点

  ![image-20220516200619382](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516200619382.png?raw=true)

- 变换矩阵（世界坐标到当前帧坐标）

  ![image-20220516200637407](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516200637407.png?raw=true)

- 求极线方程

- ![image-20220516201109481](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516201109481.png?raw=true)

- ![image-20220516201127810](https://github.com/pleasure-pan/paper/blob/image/blog/image-20220516201127810.png?raw=true)

- 判断之后删除移动点和相应地图点，如果静态对象提取的特征点可以被连续五帧跟踪但是不满足极限约束，将被转换为移动点

- **pose Fine-tuning:**有了初始相机位姿，静态特征点，动态点 ，静态可移动物体，可移动物体中改变的动态点。两步细化

  1.最小化重投影误差

  2.跟踪局部地图，投影到当前帧获取更多静态特征点。

**4.不足之处**

**5.个人想法**

乱七八糟，重新看看DS?











**1.针对问题**

**2.主要贡献**

**3.解决方法**

**4.不足之处**

**5.个人想法**
